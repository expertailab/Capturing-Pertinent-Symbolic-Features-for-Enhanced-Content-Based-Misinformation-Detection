{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from emoji import demojize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import requests\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "\n",
    "\n",
    "# Constants\n",
    "\n",
    "PLATFORM_PATH = \"https://playground.api.expertcustomers.ai/api/v1/runtime/workflow/413984e9-5955-4133-920a-4e8aa90c406f/action/analyze\"\n",
    "X_API_KEY = getpass.getpass(\"Insert expert.ai x_api_key: \")\n",
    "TAXONOMIES_PATH = \"../data/raw/taxonomies/\"\n",
    "PREPROCESSED_DATA_PATH = \"../data/processed/\"\n",
    "PROCESSED_ANNOTATED_DATA_PATH = \"../data/processed/annotated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def platform_call(text):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json; charset=utf-8',\n",
    "        'x-api-key': X_API_KEY\n",
    "    }\n",
    "    req = json.dumps({\"text\": demojize(text)})\n",
    "    response = requests.request(\"POST\", PLATFORM_PATH, headers=headers, data=req)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_schemas = {}\n",
    "for filename in os.scandir(TAXONOMIES_PATH):\n",
    "    with open(filename, \"r\") as fi:\n",
    "        taxonomy_schema = {line.strip(\"\\n\"):float(0) for line in fi.readlines()}\n",
    "        taxonomy_schemas[filename.name.split(\".\")[0]] = taxonomy_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stylo_out(output):    \n",
    "    graph = output.get(\"extraData\").get('JSON-LD').get('@graph')[0]\n",
    "    readability_idx = graph.get('readabilityIndexes')\n",
    "    readability_idx_dict = {''.join(i['name'].split()):i['value'] for i in readability_idx}\n",
    "    structure_idx = graph.get('structureIndexes')\n",
    "    structure_idx_dict = {k:float(v.get('mean', v.get('total'))) for k, v in structure_idx.items()}\n",
    "    return {**readability_idx_dict, **structure_idx_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_senti_out(output):\n",
    "    sentiment = output.get(\"sentiment\")\n",
    "    if sentiment.get(\"items\"):\n",
    "        _ = sentiment.pop(\"items\")\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(output, taxonomy_schemas):\n",
    "    schemas_deepcopy = copy.deepcopy(taxonomy_schemas)\n",
    "    for _, annotation in output.items():\n",
    "        for category in annotation[\"document\"][\"categories\"]:\n",
    "            schemas_deepcopy[category[\"namespace\"]][category[\"label\"]] = float(category[\"score\"])\n",
    "        if annotation[\"document\"].get(\"extraData\"):\n",
    "            schemas_deepcopy[\"writeprint\"] = process_stylo_out(annotation[\"document\"])\n",
    "        if annotation[\"document\"].get(\"sentiment\"):\n",
    "            schemas_deepcopy[\"sentiment\"] = process_senti_out(annotation[\"document\"])\n",
    "    return schemas_deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(text, taxonomy_schemas):\n",
    "    platform_output = platform_call(text)\n",
    "    return process_output(platform_output, taxonomy_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_vectors(text, taxonomy_schemas):\n",
    "    annotations = get_annotations(text, taxonomy_schemas)\n",
    "    tax_names = list(annotations.keys())\n",
    "    ann_values = [list(x.values()) for x in list(annotations.values())]\n",
    "    return {name:values for name, values in zip(tax_names, ann_values)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webis_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}webis.csv\")\n",
    "df2list = webis_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webis_annotated_df = pd.DataFrame.from_dict(filtered_df2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webis_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}webis.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basil_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}basil.csv\")\n",
    "df2list = basil_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basil_annotated_df = pd.DataFrame.from_dict(filtered_df2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basil_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}basil.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbait_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}clickbait.csv\")\n",
    "df2list = clickbait_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbait_annotated_df = pd.DataFrame.from_dict(filtered_df2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbait_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}clickbait.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}pheme.csv\")\n",
    "df2list = pheme_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_annotated_df = pd.DataFrame.from_dict(filtered_df2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheme_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}pheme.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politifact_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}politifact.csv\")\n",
    "df2list = politifact_df.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")\n",
    "\n",
    "politifact_annotated_df = pd.DataFrame.from_dict(filtered_df2list)\n",
    "politifact_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}politifact.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buzzfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [00:48<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation process failed for 0 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "buzzfeed_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}buzzfeed.csv\")\n",
    "\n",
    "df2list = buzzfeed_df.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")\n",
    "\n",
    "buzzfeed_annotated_df = pd.DataFrame.from_dict(filtered_df2list)\n",
    "buzzfeed_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}buzzfeed.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propaganda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propaganda_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}propaganda.csv\")\n",
    "\n",
    "df2list = propaganda_df.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")\n",
    "\n",
    "propaganda_annotated_df = pd.DataFrame.from_dict(filtered_df2list)\n",
    "propaganda_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}propaganda.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwitterCovidQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittercovidq1_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}twittercovidq1.csv\")\n",
    "\n",
    "df2list = twittercovidq1_df.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")\n",
    "\n",
    "propaganda_annotated_df = pd.DataFrame.from_dict(filtered_df2list)\n",
    "propaganda_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}twittercovidq1.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwitterCovidQ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twittercovidq2_df = pd.read_csv(f\"{PREPROCESSED_DATA_PATH}twittercovidq2.csv\")\n",
    "\n",
    "df2list = twittercovidq2_df.to_dict(\"records\")\n",
    "\n",
    "for row in tqdm(df2list):\n",
    "    try:\n",
    "        row.update(get_annotation_vectors(row[\"text\"], taxonomy_schemas))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "filtered_df2list = [item for item in df2list if len(item) == 8]\n",
    "print(f\"Annotation process failed for {len([item for item in df2list if len(item) != 8])} items\")\n",
    "\n",
    "propaganda_annotated_df = pd.DataFrame.from_dict(filtered_df2list)\n",
    "propaganda_annotated_df.to_csv(f\"{PROCESSED_ANNOTATED_DATA_PATH}twittercovidq2.csv\", index=False, header=True, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
