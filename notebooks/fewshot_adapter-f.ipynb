{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Adapter + attention features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.feature_selection import f_regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoAdapterModel,\n",
    "    AutoTokenizer,\n",
    "    PfeifferConfig,\n",
    "    TrainingArguments,\n",
    "    AdapterTrainer,\n",
    "    AutoConfig,\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Constants\n",
    "\n",
    "DATA_PATH = \"../data/annotated/\"\n",
    "MODELS_PATH = \"../models/fewshot/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train task adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_head = \"feat_att_head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"task_name\": \"twittercovidq2\",\n",
    "    \"model_name\": \"roberta-large\",\n",
    "    \"max_length\": 128,\n",
    "    \"batch_size\": 1,\n",
    "    \"epochs\": 30,\n",
    "    \"seeds\" : [0],\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"fewshot_train\": [10, 25, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_PATH = f'{DATA_PATH}{CONFIG[\"task_name\"]}.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df = pd.read_csv(TASK_PATH).dropna()\n",
    "task_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract pvals and create feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {}\n",
    "pos_labels = [\"contains-bias\", \"clickbait\", \"false\", \"fake\", \"has_propaganda\", \"yes\", \"contains_false\"]\n",
    "\n",
    "labels = set(task_df[\"labels\"].to_list())\n",
    "for label in labels:\n",
    "    if str(label).lower() in pos_labels:\n",
    "        id2label.update({1: label})\n",
    "    else:\n",
    "        id2label.update({0: label})\n",
    "\n",
    "label2id  = {id2label[k] : k for k in id2label}\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "feature_arrays = []\n",
    "for col in task_df.iloc[:,2:].columns:\n",
    "    col = task_df[col].apply(lambda x: json.loads(x))\n",
    "    col_array = np.vstack(col.values)\n",
    "    _, pvals = f_regression(col_array, task_df.iloc[:,1].apply(lambda x: label2id[x]).values)\n",
    "    selected_pval = pvals < 0.05\n",
    "    selected_features = []\n",
    "    for vector in col:\n",
    "        selected_features.append([feature for feature, pval in zip(vector, selected_pval) if pval])\n",
    "    feature_arrays.append(np.array(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.hstack(feature_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_df[\"features\"] = features.tolist()\n",
    "task_df.sample(frac=1, random_state=0)\n",
    "config = len(task_df[\"features\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation = True\n",
    "padding = \"max_length\"\n",
    "batched = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=CONFIG[\"max_length\"], truncation=truncation, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dataset = Dataset.from_pandas(task_df)\n",
    "# Encode the input data\n",
    "task_dataset = task_dataset.map(encode_batch, batched=batched)\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "task_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"features\"])\n",
    "task_dataset = task_dataset.class_encode_column(\"labels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super(MeanPooling, self).__init__()  \n",
    "        self.model_config = model_config\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatAttHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, model_config, config, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.pooler_out = torch.nn.Sequential(\n",
    "            nn.Linear(model_config.hidden_size, config[\"hidden_size\"]),\n",
    "            nn.LayerNorm(config[\"hidden_size\"], eps=1e-12),\n",
    "        )\n",
    "        self.features_out = torch.nn.Sequential(\n",
    "            nn.Linear(config[\"features_size\"], config[\"hidden_size\"]),\n",
    "            nn.LayerNorm(config[\"hidden_size\"], eps=1e-12),\n",
    "        )\n",
    "        self.out_concat = torch.nn.Sequential(\n",
    "            nn.Linear(config[\"hidden_size\"]*2, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.predictor = torch.nn.Sequential(\n",
    "            nn.Dropout(config[\"dropout\"]),\n",
    "            nn.Linear(config[\"concat_size\"], config[\"concat_size\"]),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(config[\"dropout\"]),\n",
    "            nn.Linear(config[\"concat_size\"], 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, cls_output, features, **kwargs):\n",
    "        out_pooler = self.pooler_out(cls_output)\n",
    "        out_features = self.features_out(features)\n",
    "        out = self.out_concat(torch.cat((out_pooler, out_features), dim=-1))\n",
    "\n",
    "        roberta_cls1 = cls_output * out[:,0].unsqueeze(1)\n",
    "        feature_vector1 = features * out[:,1].unsqueeze(1)\n",
    "\n",
    "        return self.predictor(torch.cat((roberta_cls1, feature_vector1), dim=1))\n",
    "    \n",
    "    def get_output_embeddings(self):\n",
    "        return None  # override for heads with output embeddings\n",
    "\n",
    "    def get_label_names(self):\n",
    "        return [\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type2head = {\"feat_att_head\": FeatAttHead}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomClassificationHead(type2head[feat_head]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        head_name,\n",
    "        num_labels=2,\n",
    "        dropout=0.1,\n",
    "        features_size=config,\n",
    "        feat_head=feat_head,\n",
    "        hidden_size=64,\n",
    "        id2label=None,\n",
    "        use_pooler=False,\n",
    "        concat_size=None\n",
    "    ):\n",
    "        self.model_config = model.config\n",
    "        self.config = {\n",
    "            \"num_labels\": num_labels,\n",
    "            \"dropout\": dropout,\n",
    "            \"label2id\": {label: id_ for id_, label in id2label.items()} if id2label is not None else None,\n",
    "            \"use_pooler\": use_pooler,\n",
    "            \"features_size\": features_size,\n",
    "            \"feat_head\": feat_head,\n",
    "            \"hidden_size\": hidden_size,\n",
    "            \"concat_size\": concat_size if concat_size is not None else self.model_config.hidden_size+features_size,\n",
    "        }\n",
    "        super().__init__(self.model_config, self.config, head_name)\n",
    "        \n",
    "        self.apply(model._init_weights)\n",
    "        self.train(model.training)  # make sure training mode is consistent\n",
    "\n",
    "    def forward(self, outputs, cls_output=None, attention_mask=None, return_dict=False, **kwargs):\n",
    "        if cls_output is None:\n",
    "            if self.config[\"use_pooler\"]:\n",
    "                pooler = MeanPooling(self.model_config).to(\"cuda\")\n",
    "                cls_output = pooler(outputs.last_hidden_state, attention_mask)\n",
    "        features = kwargs.pop(\"features\", None)\n",
    "        logits = super().forward(cls_output, features)\n",
    "        loss = None\n",
    "        labels = kwargs.pop(\"labels\", None)\n",
    "        if labels is not None:\n",
    "            if self.config[\"num_labels\"] == 1:\n",
    "                #  We are doing regression\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.config[\"num_labels\"]), labels.view(-1))\n",
    "\n",
    "        if return_dict:\n",
    "            return SequenceClassifierOutput(\n",
    "                loss=loss,\n",
    "                logits=logits,\n",
    "                hidden_states=outputs.hidden_states,\n",
    "                attentions=outputs.attentions,\n",
    "            )\n",
    "        else:\n",
    "            outputs = (logits,) + outputs[1:]\n",
    "            if labels is not None:\n",
    "                outputs = (loss,) + outputs\n",
    "            return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdapterDropTrainerCallback(TrainerCallback):\n",
    "  def on_step_begin(self, args, state, control, **kwargs):\n",
    "    skip_layers = list(range(np.random.randint(0, 11)))\n",
    "    kwargs['model'].set_active_adapters(kwargs['model'].active_adapters[0], skip_layers=skip_layers)\n",
    "\n",
    "  def on_evaluate(self, args, state, control, **kwargs):\n",
    "    # Deactivate skipping layers during evaluation (otherwise it would use the\n",
    "    # previous randomly chosen skip_layers and thus yield results not comparable\n",
    "    # across different epochs)\n",
    "    kwargs['model'].set_active_adapters(kwargs['model'].active_adapters[0], skip_layers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_and_f1(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = float(f1_score(y_true, y_pred, average='macro'))\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return acc_and_f1(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"epoch\"\n",
    "output_dir = f'{MODELS_PATH}{CONFIG[\"model_name\"]}{os.sep}att-adapt{os.sep}{CONFIG[\"task_name\"]}'\n",
    "overwrite_output_dir = True\n",
    "remove_unused_columns = False\n",
    "save_total_limit = 1\n",
    "report_to = \"wandb\"\n",
    "load_best_model_at_end = True\n",
    "metric_for_best_model = \"eval_f1\"\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model_config = AutoConfig.from_pretrained(\n",
    "        CONFIG[\"model_name\"],\n",
    "        id2label=id2label,\n",
    "    )\n",
    "    task_model = AutoAdapterModel.from_pretrained(\n",
    "        CONFIG[\"model_name\"],\n",
    "        config=model_config,\n",
    "    )\n",
    "    adapter_config = PfeifferConfig()\n",
    "    task_model.add_adapter(CONFIG[\"task_name\"], config=adapter_config)\n",
    "    task_model.train_adapter(CONFIG[\"task_name\"])\n",
    "    task_model.set_active_adapters(CONFIG[\"task_name\"])\n",
    "    task_model.register_custom_head(\"custom_classification\", CustomClassificationHead)\n",
    "    task_model.add_custom_head(\n",
    "        \"custom_classification\",\n",
    "        head_name=CONFIG[\"task_name\"],\n",
    "        num_labels=len(id2label),\n",
    "        use_pooler=True,\n",
    "        id2label=id2label,\n",
    "    )\n",
    "    return task_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs in CONFIG[\"fewshot_train\"]:\n",
    "    fewshot_train_ratio = np.ceil(fs/len(task_df)*100)\n",
    "    for seed in CONFIG[\"seeds\"]:\n",
    "        wandb.init(\n",
    "            project=CONFIG[\"task_name\"], \n",
    "            config=CONFIG,\n",
    "            job_type=f'{CONFIG[\"model_name\"]}_{fs}',\n",
    "            group=feat_head,\n",
    "            tags=[\n",
    "                feat_head,\n",
    "                CONFIG['model_name'],\n",
    "                f\"mx: {CONFIG['max_length']}\",\n",
    "                f\"bs: {CONFIG['batch_size']}\",\n",
    "                f\"ep: {CONFIG['epochs']}\",\n",
    "                f\"lr: {CONFIG['learning_rate']}\",\n",
    "            ],\n",
    "            name=f'seed_{seed}',\n",
    "            anonymous='must'\n",
    "        )\n",
    "\n",
    "        train_test = task_dataset.train_test_split(test_size=(100-fewshot_train_ratio)/100, generator=np.random.RandomState(0))\n",
    "        test_valid = train_test['test'].train_test_split(test_size=0.2, generator=np.random.RandomState(0))\n",
    "        \n",
    "        dataset = DatasetDict(\n",
    "            {\n",
    "                'train': train_test['train'],\n",
    "                'valid': test_valid['test'],\n",
    "                'test': test_valid['train']\n",
    "            }\n",
    "        )\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            learning_rate=CONFIG[\"learning_rate\"],\n",
    "            num_train_epochs=CONFIG[\"epochs\"],\n",
    "            per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "            per_device_eval_batch_size=CONFIG[\"batch_size\"],\n",
    "            gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "            logging_strategy=strategy,\n",
    "            evaluation_strategy=strategy,\n",
    "            save_strategy=strategy,\n",
    "            output_dir=output_dir,\n",
    "            overwrite_output_dir=overwrite_output_dir,\n",
    "            # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "            remove_unused_columns=remove_unused_columns,\n",
    "            save_total_limit=save_total_limit,\n",
    "            report_to=report_to,\n",
    "            load_best_model_at_end=load_best_model_at_end,\n",
    "            metric_for_best_model=metric_for_best_model,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model_init=get_model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"valid\"],\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks = [\n",
    "                EarlyStoppingCallback(early_stopping_patience=early_stopping_patience),\n",
    "                AdapterDropTrainerCallback()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        trainer.evaluate(dataset[\"test\"], metric_key_prefix=\"test\")\n",
    "\n",
    "        wandb.finish()\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
